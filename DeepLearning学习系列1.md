深度学习和人工智能
=====
### 背景
略

### 定义
****机器学习*：是一门专门研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善自身的性能的学科。

机器学习未解决的问题如：图像识别，语音识别，自然语言理解，天气预测，基因表达，内容推荐，空间数据等等，以视觉感知为例：
包括 获取数据->预处理->特征提取->特征选择->推理、预测或识别    中间的三个部分，是特征表达，对最终算法的准确性起来了关键
作用，而且系统的主要计算和测试工作都在这一大部分。但一般都是人工完成的，靠人工提取特征

深度学习的故事来源：
[人脑的视觉机理](http://blog.csdn.net/zouxy09/article/details/8775360/)

深度学习的关键在于分层，而且是多层，不同层次做不同程度的抽象，以致于从最初的像素到最后的抽象语义特征
不同的层次都需要抽取相应的特征，怎么去提取特征是个关键

稀疏编码sparse coding
初级的特征----复杂图形，往往由一些基本结构edge组成
更结构化，更复杂的，具有概念性的图形，需要更高层次的特征表示 

对深度学习而言，任何一种方法，特征越多，给出的参考信息就越多，准确性就会得到提升，但特征多意味着计算复杂，探索空间大，可以用来训练的数据在
每个特征上就会稀疏，都会带来问题，并不一定特征越多越好

Deep learning：让机器自动学习良好的特征，而免去人工选取过程，还有参考人的分层视觉处理系统，我们得到一个结论就是：Deep learning 需要多层来获
得更抽象的的特征表达

###浅层学习和深度学习
*浅层学习*
====
常用算法：
用于人工神经网络的反射传播算法(Back Propagation,也叫BP)：可以让一个人工神经网络模型从大量训练样本中学习统计规律，从而对未知事件做预测
支撑向量机（SVM，Support Vector Machines）:
Boosting:
最大熵方法（如LR， Logistic Regression）：
这些模型的结构基本上可以看成带有一层隐层节点（如SVM，Boosting）,或没有隐层节点（如LR）。

浅层学习与深度学习的区别
====
浅层结构算法，其局限性在于有限样本和计算单元情况下，对复杂函数的表示能力有限，针对复杂分类问题，其泛化能力受到一定制约。
而深度学习可通过学习一种深层非线性网络结构，实现复杂函数逼近，表征输入数据分布式表示，并展现了强大的从少数样本集中学习数据
集本质特征的能力。

深度学习
====
深度学习的实质，是通过构建具有很多隐层的机器学习模型和少量的训练数据，来学习更有用的特征，从而最终提升分类或预测的准确性。
因此，“深度模型”是手段，“特征学习”是目的。
深度学习的不同：
1. 强调了模型结构的深度，通常有5层、6层，甚至10多层的隐层节点；
2. 明确突出了特征学习的重要性，也主是说，通过逐层特征变换，将样本在原空间的特征表示变换到新特征空间，
从而使分类或预测更加容易。

深度学习与神经网络
====
相同点：系统由包括输入层、隐层、输出层组成的多层网络，只有相邻层节点之间有连接，同一层及跨层节点之间无连接，每一层可以看作一个Logistic Regression模型；
不同点：传统的神经网络，采用Back Propagation的方式进行；而Deep learning 整体上是一个 layer-wise 的训练机制。因为采用原来的方式的话，对于多层的Deep Network,
残差传播到最前面的层已经变得太小，出现所谓的gradient diffusion(梯度扩散)

Deep learning 训练过程
1. 首先逐层构建单层神经元，这样每次都是训练一个单层网络。
2. 当所有层训练完成, Hinton 使用 wake-sleep 算法进行调优

wake-sleep 算法：
将除最顶层的其它层间的权重变为双向的，这样最顶层是一个单层神经网络，而其它层则变为了图模型。向上的权重用于“认知”，向下的权重用于“生成”。
然后使用 wake-sleep 调整所有的权重，让认识和生成达成一致，也就是保证生成的最顶层表示能够尽可能正确的复原底层的特点，
比如顶层的一个结点表示人脸，那么所有人脸的图像应该激活这个结点（认识），并且这个结果向下生成的图像应该能够表现为一个大概的人脸图像（生成）。
wake-sleep 算法分为醒和睡两个部分：
1） wake:认识过程，通过处界的特征和向上的认知权重，产生每一层的结点状态（即该层的抽象表示），并且使用梯度下降修改层间的生成权重（向下的生成权重）。
也就是：如果现实（下一层抽象表示的结果）跟我想的（通过特征和认知权重得到当前层的抽象表示）不一样，就改变我的权重（生成）使得我想象的东西
（生成的下一层抽象表示结果）就是这样的。（注：括号内是我自己的理解，原文太抽象了）
2） sleep：生成过程，通过顶层表示（即醒时学得的概念，就学习得到的特征）和向下权重，生成底层的状态，同时修改层间向上的权重。
也就是：如果梦中的景象（下一层的抽象表示）不是我脑中的的相应概念（当前层的抽象表示，学习到的特征），改变我的认识权重使得景象
在我看来就是这个概念。
