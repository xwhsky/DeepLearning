### deep learning 的常用模型或方法
=====
1、AutoEncoder 自动编码器
    最简单的方法是利用人工神经网络（ANN），ANN 本身就是具有层次结构的系统，给定一个神经网络，假设其输出与输入是相同的，然后训练调整其参数，得到每一层中的权重。
    这样，我们得到了输入的几种不同表示，这些表示就是特征。
    自动编码器就是尽可能复现这种输入信号的神经网络。为了实现这种复现，自动编码器就必须捕捉可以代表输入数据的最重要的因素，就像PCA（主成分分析一样，
    找到可以代表原信息的主要成分）
 1.1 Sparsing Code AutoEncoder 稀疏自动编码器
 1.2 Denoising AutoEncoder 降噪自动编码器
2、 Sparsing Code 稀疏编码
    它用来寻找一组“超完备”基向量来高效地表示样本。与主成分分析（PCA）不同的是，稀疏编码所寻找的基向量的个数比输入向量的维数要大，而且系统Aj不再由输入向量唯一确定
    ，因此在稀疏编码算法中，我们加入了一个证券标准“稀疏性”来解决因超完备而导致的退化问题。

    我的疑问：基向量是如何自动生成的？
    1. Training 阶段：
    给定一系列的样本图片[x1, x2, ...], 我们需要学习得到一组基·[o1, o2, ...], 也就是字典
    稀疏编码是 K-means 算法的变体，训练过程差不多（EM 算法的思想：如果要优化的目标函数包含两个变量，如L（W，B），那么我们可以先固定W，调整B使得L最小，然后
    再固定B，调整W使L最小，这样迭代交替，不断将L推向最小值），这里的迭代分两步：
    1） 固定字典o[k],然后调整a[k]，使得目标函数最小（即解LASSO问题）。
    2） 然后固定a[k],调整o[k],使目标函数最小（即解凸QP问题）
    2. Coding 阶段：
    给定一个新的图片x，由上面得到的字典，通过解一个 LASSO 问题得到稀疏向量 a。这个稀疏向量就是这个输入向量x的一个稀疏表达了。

3、 Restricted Boltzmann Machine (RBM)限制波尔兹曼机

