#标题：卷积神经网络的应用研究介绍
>参考文献：《基于卷积神经网络的深度学习与算法研究》 陈先昌 浙江工商大学

##深度学习发展阶段
###第一阶段：浅层学习（shallow learning）
>**特点：只包含一层隐藏层节点**

1980's：反向传播算法（Back Propagation，BP）的出现，引领了基于统计机器学习模型的发展浪潮<p>
1990's：<p>
　　最大熵法（Logistic Regression）<p>
　　Boosting<p>
　　支持向量机（SVM，Support Vector Machines）<p>
　　...<p>
2010's:浅层学习在海量互联网数据的成功应用（对大数据智能分析和预测）<p>
　　网页搜索排序系统（如微软Bing）<p>
　　搜索广告系统（百度的“凤巢”、谷歌的AdWords）<p>
　　内容推荐系统<p>
　　垃圾邮件过滤<p>
　　...<p>
###第二阶段：深度学习（deep learning）
>**特点：1. 包含多层隐藏层节点，其隐层节点的层数在5层以上**   
**2. 明确强调了特征学习对于深度模型的重要性，即通过逐层特征提取，将数据样本在原空间的特征变换到一个新的特征空间来表示初始数据，这使得分类或预测问题更加容易实现。**

2006年：    
Geoffrey Hinton及其学生Ruslan发表在《科学》上的论文[《Reducing the dimensionality of data with neural networks》](https://www.cs.toronto.edu/~hinton/science.pdf)   
1. 多层人工神经网络模型有很强的特征学习能力，深度学习模型学习得到的特征数据对原数据有更本质的代表性，这将大大便于分类和可视化问题；   
2. 对于深度神经网络很难训练达到最优的问题，可以釆用逐层训练方法解决。将上层训练好的结果作为下层训练过程中的初始化参数   
2011年：谷歌和微软的语音识别采用深度神经网络将语音识别的错误率降低20%-30%，取得重大突破   
2012年：    
1. 深度神经网络在图像识别应用方面取得重大进展，ImageNet测评中降低了错误率9%      
2. 谷歌神X实验室创建了一个有个处理器的大规模神经网络，包含数十亿个网络节点。以大量随机选择的视频片段进行训练，可以识别猫的图像。  



##深度学习应用
###更多应用
http://mp.weixin.qq.com/s?__biz=MzA5NzkxMzg1Nw==&mid=2653159186&idx=1&sn=6960170eb1eb9a8ce64163f9ba5caec4&scene=0#wechat_redirect
###语音识别
###图像识别
1989年：卷积神经网络提出，初步应用    
2012年：Hinton构建的深度学习网络引入权重衰减的概念，有效地减少权重幅度，防止网络过拟合。其模型在ImageNet问题上取得了世界最好成果。它的另外一个特点：直接对原始图像进行训练，不需要额外的人工特征提取操作    
###自然语言处理


##深度学习存在的问题
一个是关于统计学习，另一个和计算量相关。相对浅层学习模型来说，深度学习模型对非线性函数的表示能力更好。根据通用的神经网络逼近理论，对任何一个非线性函数来说，都可以由一个浅层模型和一个深度学习模型很好的表示，但相对浅层模型，深度学习模型需要较少的参数。关于深度学习训练的计算复杂度也是我们需要关心的问题，即我们需要多大参数规模和深度的神经网络模型去解决相应的问题，在对构建好的网络进行训练时，需要多少训练样本才能足以使网络满足拟合状态。

